{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multi-class-classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnTS2ue9E2pf"
      },
      "source": [
        "**# This is and end-to-end image classification project.**\n",
        "\n",
        "**# In this project, we will train a CNN to classify images from the CIFAR-10 dataset, a subset of the 80 Million Tiny Images and consists of 60,000 (32 Ã— 32) color images containing 1 of 10 object classes, with 6,000 images per class.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuIj71mgFfmw"
      },
      "source": [
        "# ***STEP 1: IMPORT DEPENDENCIES***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkpy4uAUfMH7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8li-yVb1F5S8"
      },
      "source": [
        "# **STEP 2: GET THE DATA READY FOR TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffw2tT7nf2HQ",
        "outputId": "8d9e33e1-5054-44ac-a2b1-d38b7b735aad"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()                    # load preshuffled train and test data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "print('x_train =', x_train.shape)\n",
        "print('x_valid =', x_valid.shape)\n",
        "print('x_test =', x_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train = (45000, 32, 32, 3)\n",
            "x_valid = (5000, 32, 32, 3)\n",
            "x_test = (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-JsQRBtGIyQ"
      },
      "source": [
        "# **Normalize the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzJ2gPXofK_D"
      },
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_valid = (x_valid-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGqFMvQtGO2G"
      },
      "source": [
        "# **One-hot encode the labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk9V390kffpw"
      },
      "source": [
        "num_classes = len(np.unique(y_train))\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_valid = np_utils.to_categorical(y_valid, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aw-zVcbGT-e"
      },
      "source": [
        "# **Data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLIG6f8hgGow"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = False\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ossz0OnCGYW2"
      },
      "source": [
        "# **STEP 3: BUILD THE MODEL ARCHITECTURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i86SkrTvi2gD",
        "outputId": "75d01565-7b06-4311-805f-fb5ec7b3267e"
      },
      "source": [
        "base_hidden_units = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential([\n",
        "                    Conv2D(input_shape = x_train.shape[1:], filters = base_hidden_units, kernel_size = 3, padding = 'same', kernel_regularizer = regularizers.l2(weight_decay)),\n",
        "                    Activation('relu'),\n",
        "                    BatchNormalization(),\n",
        "                    Conv2D(filters = base_hidden_units * 2, kernel_size = 3, padding = 'same', kernel_regularizer = regularizers.l2(weight_decay)),\n",
        "                    Activation('relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D(pool_size=(2,2)),\n",
        "                    Dropout(0.2),\n",
        "                    Conv2D(filters = base_hidden_units * 2, kernel_size = 3, padding = 'same', kernel_regularizer = regularizers.l2(weight_decay)),\n",
        "                    Activation('relu'),\n",
        "                    BatchNormalization(),\n",
        "                    Conv2D(filters = base_hidden_units * 2, kernel_size = 3, padding = 'same', kernel_regularizer = regularizers.l2(weight_decay)),\n",
        "                    Activation('relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D(pool_size=(2,2)),\n",
        "                    Dropout(0.3),\n",
        "                    Conv2D(filters = base_hidden_units * 4, kernel_size = 3, padding = 'same', kernel_regularizer = regularizers.l2(weight_decay)),\n",
        "                    Activation('relu'),\n",
        "                    BatchNormalization(),\n",
        "                    Conv2D(filters = base_hidden_units * 4, kernel_size = 3, padding = 'same', kernel_regularizer = regularizers.l2(weight_decay)),\n",
        "                    Activation('relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D(pool_size=(2,2)),\n",
        "                    Dropout(0.4),\n",
        "                    Flatten(),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 337,098\n",
            "Trainable params: 336,138\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZoSvOxdGg-P"
      },
      "source": [
        "# **STEP 4: TRAIN THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tBnToMofIzB",
        "outputId": "88b9d890-0d21-44c2-97d7-2a39d302685a"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 200\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "optimizer = optimizers.Adam(lr=0.0001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                              callbacks=[checkpointer],\n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              epochs=epochs,\n",
        "                              verbose=2, validation_data=(x_valid, y_valid))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "351/351 - 34s - loss: 2.8343 - accuracy: 0.2739 - val_loss: 2.2957 - val_accuracy: 0.2466\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.29575, saving model to model.weights.best.hdf5\n",
            "Epoch 2/200\n",
            "351/351 - 30s - loss: 2.1012 - accuracy: 0.3661 - val_loss: 1.5333 - val_accuracy: 0.4710\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.29575 to 1.53334, saving model to model.weights.best.hdf5\n",
            "Epoch 3/200\n",
            "351/351 - 30s - loss: 1.8496 - accuracy: 0.4087 - val_loss: 1.5078 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.53334 to 1.50784, saving model to model.weights.best.hdf5\n",
            "Epoch 4/200\n",
            "351/351 - 31s - loss: 1.7108 - accuracy: 0.4462 - val_loss: 1.4458 - val_accuracy: 0.5008\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.50784 to 1.44583, saving model to model.weights.best.hdf5\n",
            "Epoch 5/200\n",
            "351/351 - 30s - loss: 1.6028 - accuracy: 0.4788 - val_loss: 1.4337 - val_accuracy: 0.5154\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.44583 to 1.43368, saving model to model.weights.best.hdf5\n",
            "Epoch 6/200\n",
            "351/351 - 30s - loss: 1.5084 - accuracy: 0.5062 - val_loss: 1.3377 - val_accuracy: 0.5450\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.43368 to 1.33774, saving model to model.weights.best.hdf5\n",
            "Epoch 7/200\n",
            "351/351 - 30s - loss: 1.4290 - accuracy: 0.5308 - val_loss: 1.3371 - val_accuracy: 0.5546\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.33774 to 1.33711, saving model to model.weights.best.hdf5\n",
            "Epoch 8/200\n",
            "351/351 - 30s - loss: 1.3715 - accuracy: 0.5489 - val_loss: 1.3168 - val_accuracy: 0.5598\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.33711 to 1.31679, saving model to model.weights.best.hdf5\n",
            "Epoch 9/200\n",
            "351/351 - 30s - loss: 1.3117 - accuracy: 0.5668 - val_loss: 1.3318 - val_accuracy: 0.5672\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.31679\n",
            "Epoch 10/200\n",
            "351/351 - 30s - loss: 1.2684 - accuracy: 0.5830 - val_loss: 1.2299 - val_accuracy: 0.5898\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.31679 to 1.22989, saving model to model.weights.best.hdf5\n",
            "Epoch 11/200\n",
            "351/351 - 30s - loss: 1.2214 - accuracy: 0.5973 - val_loss: 1.2059 - val_accuracy: 0.5978\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.22989 to 1.20593, saving model to model.weights.best.hdf5\n",
            "Epoch 12/200\n",
            "351/351 - 30s - loss: 1.1763 - accuracy: 0.6099 - val_loss: 1.2188 - val_accuracy: 0.6018\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.20593\n",
            "Epoch 13/200\n",
            "351/351 - 30s - loss: 1.1441 - accuracy: 0.6245 - val_loss: 1.0652 - val_accuracy: 0.6400\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.20593 to 1.06519, saving model to model.weights.best.hdf5\n",
            "Epoch 14/200\n",
            "351/351 - 30s - loss: 1.1000 - accuracy: 0.6343 - val_loss: 1.1280 - val_accuracy: 0.6318\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.06519\n",
            "Epoch 15/200\n",
            "351/351 - 30s - loss: 1.0672 - accuracy: 0.6478 - val_loss: 0.9979 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.06519 to 0.99792, saving model to model.weights.best.hdf5\n",
            "Epoch 16/200\n",
            "351/351 - 30s - loss: 1.0433 - accuracy: 0.6513 - val_loss: 1.0227 - val_accuracy: 0.6590\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.99792\n",
            "Epoch 17/200\n",
            "351/351 - 30s - loss: 1.0135 - accuracy: 0.6650 - val_loss: 1.0090 - val_accuracy: 0.6664\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.99792\n",
            "Epoch 18/200\n",
            "351/351 - 30s - loss: 0.9854 - accuracy: 0.6728 - val_loss: 1.0270 - val_accuracy: 0.6702\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.99792\n",
            "Epoch 19/200\n",
            "351/351 - 31s - loss: 0.9596 - accuracy: 0.6800 - val_loss: 0.9386 - val_accuracy: 0.6952\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.99792 to 0.93864, saving model to model.weights.best.hdf5\n",
            "Epoch 20/200\n",
            "351/351 - 30s - loss: 0.9367 - accuracy: 0.6872 - val_loss: 0.8697 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.93864 to 0.86972, saving model to model.weights.best.hdf5\n",
            "Epoch 21/200\n",
            "351/351 - 30s - loss: 0.9172 - accuracy: 0.6950 - val_loss: 0.8875 - val_accuracy: 0.7158\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.86972\n",
            "Epoch 22/200\n",
            "351/351 - 30s - loss: 0.8946 - accuracy: 0.7021 - val_loss: 0.9263 - val_accuracy: 0.7046\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.86972\n",
            "Epoch 23/200\n",
            "351/351 - 30s - loss: 0.8792 - accuracy: 0.7079 - val_loss: 0.8831 - val_accuracy: 0.7202\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.86972\n",
            "Epoch 24/200\n",
            "351/351 - 30s - loss: 0.8561 - accuracy: 0.7135 - val_loss: 0.8653 - val_accuracy: 0.7250\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.86972 to 0.86528, saving model to model.weights.best.hdf5\n",
            "Epoch 25/200\n",
            "351/351 - 30s - loss: 0.8455 - accuracy: 0.7200 - val_loss: 0.8384 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.86528 to 0.83841, saving model to model.weights.best.hdf5\n",
            "Epoch 26/200\n",
            "351/351 - 30s - loss: 0.8253 - accuracy: 0.7258 - val_loss: 0.8315 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.83841 to 0.83149, saving model to model.weights.best.hdf5\n",
            "Epoch 27/200\n",
            "351/351 - 30s - loss: 0.8113 - accuracy: 0.7301 - val_loss: 0.7807 - val_accuracy: 0.7510\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.83149 to 0.78071, saving model to model.weights.best.hdf5\n",
            "Epoch 28/200\n",
            "351/351 - 30s - loss: 0.8011 - accuracy: 0.7315 - val_loss: 0.8002 - val_accuracy: 0.7396\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.78071\n",
            "Epoch 29/200\n",
            "351/351 - 30s - loss: 0.7820 - accuracy: 0.7408 - val_loss: 0.7751 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.78071 to 0.77514, saving model to model.weights.best.hdf5\n",
            "Epoch 30/200\n",
            "351/351 - 30s - loss: 0.7716 - accuracy: 0.7445 - val_loss: 0.7429 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.77514 to 0.74293, saving model to model.weights.best.hdf5\n",
            "Epoch 31/200\n",
            "351/351 - 30s - loss: 0.7583 - accuracy: 0.7465 - val_loss: 0.7562 - val_accuracy: 0.7598\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.74293\n",
            "Epoch 32/200\n",
            "351/351 - 30s - loss: 0.7472 - accuracy: 0.7510 - val_loss: 0.7355 - val_accuracy: 0.7620\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.74293 to 0.73552, saving model to model.weights.best.hdf5\n",
            "Epoch 33/200\n",
            "351/351 - 30s - loss: 0.7420 - accuracy: 0.7552 - val_loss: 0.7468 - val_accuracy: 0.7592\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.73552\n",
            "Epoch 34/200\n",
            "351/351 - 30s - loss: 0.7339 - accuracy: 0.7581 - val_loss: 0.7405 - val_accuracy: 0.7634\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.73552\n",
            "Epoch 35/200\n",
            "351/351 - 30s - loss: 0.7245 - accuracy: 0.7599 - val_loss: 0.7275 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.73552 to 0.72749, saving model to model.weights.best.hdf5\n",
            "Epoch 36/200\n",
            "351/351 - 30s - loss: 0.7132 - accuracy: 0.7651 - val_loss: 0.7146 - val_accuracy: 0.7728\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.72749 to 0.71455, saving model to model.weights.best.hdf5\n",
            "Epoch 37/200\n",
            "351/351 - 30s - loss: 0.7066 - accuracy: 0.7661 - val_loss: 0.6971 - val_accuracy: 0.7786\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.71455 to 0.69707, saving model to model.weights.best.hdf5\n",
            "Epoch 38/200\n",
            "351/351 - 30s - loss: 0.6879 - accuracy: 0.7754 - val_loss: 0.7273 - val_accuracy: 0.7722\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.69707\n",
            "Epoch 39/200\n",
            "351/351 - 30s - loss: 0.6847 - accuracy: 0.7746 - val_loss: 0.6717 - val_accuracy: 0.7860\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.69707 to 0.67172, saving model to model.weights.best.hdf5\n",
            "Epoch 40/200\n",
            "351/351 - 30s - loss: 0.6782 - accuracy: 0.7762 - val_loss: 0.6946 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.67172\n",
            "Epoch 41/200\n",
            "351/351 - 30s - loss: 0.6696 - accuracy: 0.7794 - val_loss: 0.7088 - val_accuracy: 0.7834\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.67172\n",
            "Epoch 42/200\n",
            "351/351 - 30s - loss: 0.6640 - accuracy: 0.7838 - val_loss: 0.6443 - val_accuracy: 0.7914\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.67172 to 0.64434, saving model to model.weights.best.hdf5\n",
            "Epoch 43/200\n",
            "351/351 - 30s - loss: 0.6510 - accuracy: 0.7840 - val_loss: 0.6825 - val_accuracy: 0.7846\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.64434\n",
            "Epoch 44/200\n",
            "351/351 - 30s - loss: 0.6483 - accuracy: 0.7870 - val_loss: 0.6554 - val_accuracy: 0.7916\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.64434\n",
            "Epoch 45/200\n",
            "351/351 - 30s - loss: 0.6414 - accuracy: 0.7888 - val_loss: 0.6706 - val_accuracy: 0.7920\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.64434\n",
            "Epoch 46/200\n",
            "351/351 - 30s - loss: 0.6365 - accuracy: 0.7893 - val_loss: 0.6511 - val_accuracy: 0.7920\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.64434\n",
            "Epoch 47/200\n",
            "351/351 - 30s - loss: 0.6277 - accuracy: 0.7938 - val_loss: 0.6392 - val_accuracy: 0.8004\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.64434 to 0.63916, saving model to model.weights.best.hdf5\n",
            "Epoch 48/200\n",
            "351/351 - 30s - loss: 0.6165 - accuracy: 0.7979 - val_loss: 0.6049 - val_accuracy: 0.8094\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.63916 to 0.60486, saving model to model.weights.best.hdf5\n",
            "Epoch 49/200\n",
            "351/351 - 30s - loss: 0.6199 - accuracy: 0.7968 - val_loss: 0.5809 - val_accuracy: 0.8240\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.60486 to 0.58087, saving model to model.weights.best.hdf5\n",
            "Epoch 50/200\n",
            "351/351 - 30s - loss: 0.6138 - accuracy: 0.7993 - val_loss: 0.6237 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.58087\n",
            "Epoch 51/200\n",
            "351/351 - 30s - loss: 0.6061 - accuracy: 0.8019 - val_loss: 0.6071 - val_accuracy: 0.8148\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.58087\n",
            "Epoch 52/200\n",
            "351/351 - 30s - loss: 0.6014 - accuracy: 0.8034 - val_loss: 0.6035 - val_accuracy: 0.8068\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.58087\n",
            "Epoch 53/200\n",
            "351/351 - 30s - loss: 0.5915 - accuracy: 0.8072 - val_loss: 0.6087 - val_accuracy: 0.8086\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.58087\n",
            "Epoch 54/200\n",
            "351/351 - 30s - loss: 0.5912 - accuracy: 0.8074 - val_loss: 0.6281 - val_accuracy: 0.8038\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.58087\n",
            "Epoch 55/200\n",
            "351/351 - 30s - loss: 0.5839 - accuracy: 0.8101 - val_loss: 0.5777 - val_accuracy: 0.8182\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.58087 to 0.57766, saving model to model.weights.best.hdf5\n",
            "Epoch 56/200\n",
            "351/351 - 30s - loss: 0.5803 - accuracy: 0.8109 - val_loss: 0.6173 - val_accuracy: 0.8090\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.57766\n",
            "Epoch 57/200\n",
            "351/351 - 30s - loss: 0.5736 - accuracy: 0.8141 - val_loss: 0.5642 - val_accuracy: 0.8212\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.57766 to 0.56419, saving model to model.weights.best.hdf5\n",
            "Epoch 58/200\n",
            "351/351 - 30s - loss: 0.5717 - accuracy: 0.8152 - val_loss: 0.5850 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.56419\n",
            "Epoch 59/200\n",
            "351/351 - 30s - loss: 0.5705 - accuracy: 0.8155 - val_loss: 0.5468 - val_accuracy: 0.8268\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.56419 to 0.54680, saving model to model.weights.best.hdf5\n",
            "Epoch 60/200\n",
            "351/351 - 30s - loss: 0.5600 - accuracy: 0.8169 - val_loss: 0.6190 - val_accuracy: 0.8086\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.54680\n",
            "Epoch 61/200\n",
            "351/351 - 30s - loss: 0.5576 - accuracy: 0.8192 - val_loss: 0.5599 - val_accuracy: 0.8220\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.54680\n",
            "Epoch 62/200\n",
            "351/351 - 30s - loss: 0.5524 - accuracy: 0.8210 - val_loss: 0.5300 - val_accuracy: 0.8330\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.54680 to 0.53002, saving model to model.weights.best.hdf5\n",
            "Epoch 63/200\n",
            "351/351 - 30s - loss: 0.5526 - accuracy: 0.8194 - val_loss: 0.5498 - val_accuracy: 0.8298\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.53002\n",
            "Epoch 64/200\n",
            "351/351 - 30s - loss: 0.5434 - accuracy: 0.8261 - val_loss: 0.5293 - val_accuracy: 0.8356\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.53002 to 0.52933, saving model to model.weights.best.hdf5\n",
            "Epoch 65/200\n",
            "351/351 - 30s - loss: 0.5399 - accuracy: 0.8241 - val_loss: 0.5432 - val_accuracy: 0.8278\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.52933\n",
            "Epoch 66/200\n",
            "351/351 - 30s - loss: 0.5393 - accuracy: 0.8259 - val_loss: 0.5454 - val_accuracy: 0.8272\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.52933\n",
            "Epoch 67/200\n",
            "351/351 - 30s - loss: 0.5349 - accuracy: 0.8257 - val_loss: 0.5274 - val_accuracy: 0.8354\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.52933 to 0.52737, saving model to model.weights.best.hdf5\n",
            "Epoch 68/200\n",
            "351/351 - 30s - loss: 0.5290 - accuracy: 0.8290 - val_loss: 0.5454 - val_accuracy: 0.8272\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.52737\n",
            "Epoch 69/200\n",
            "351/351 - 30s - loss: 0.5349 - accuracy: 0.8274 - val_loss: 0.5170 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.52737 to 0.51696, saving model to model.weights.best.hdf5\n",
            "Epoch 70/200\n",
            "351/351 - 30s - loss: 0.5273 - accuracy: 0.8286 - val_loss: 0.5109 - val_accuracy: 0.8362\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.51696 to 0.51089, saving model to model.weights.best.hdf5\n",
            "Epoch 71/200\n",
            "351/351 - 30s - loss: 0.5212 - accuracy: 0.8301 - val_loss: 0.5251 - val_accuracy: 0.8354\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.51089\n",
            "Epoch 72/200\n",
            "351/351 - 30s - loss: 0.5205 - accuracy: 0.8328 - val_loss: 0.5125 - val_accuracy: 0.8376\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.51089\n",
            "Epoch 73/200\n",
            "351/351 - 30s - loss: 0.5146 - accuracy: 0.8347 - val_loss: 0.5326 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.51089\n",
            "Epoch 74/200\n",
            "351/351 - 30s - loss: 0.5128 - accuracy: 0.8363 - val_loss: 0.5221 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.51089\n",
            "Epoch 75/200\n",
            "351/351 - 30s - loss: 0.5026 - accuracy: 0.8372 - val_loss: 0.5117 - val_accuracy: 0.8400\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.51089\n",
            "Epoch 76/200\n",
            "351/351 - 30s - loss: 0.5020 - accuracy: 0.8370 - val_loss: 0.5311 - val_accuracy: 0.8330\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.51089\n",
            "Epoch 77/200\n",
            "351/351 - 30s - loss: 0.4999 - accuracy: 0.8385 - val_loss: 0.5000 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.51089 to 0.50004, saving model to model.weights.best.hdf5\n",
            "Epoch 78/200\n",
            "351/351 - 30s - loss: 0.4970 - accuracy: 0.8403 - val_loss: 0.5209 - val_accuracy: 0.8410\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.50004\n",
            "Epoch 79/200\n",
            "351/351 - 30s - loss: 0.4958 - accuracy: 0.8412 - val_loss: 0.4810 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.50004 to 0.48101, saving model to model.weights.best.hdf5\n",
            "Epoch 80/200\n",
            "351/351 - 30s - loss: 0.4884 - accuracy: 0.8428 - val_loss: 0.4702 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.48101 to 0.47015, saving model to model.weights.best.hdf5\n",
            "Epoch 81/200\n",
            "351/351 - 30s - loss: 0.4914 - accuracy: 0.8427 - val_loss: 0.4740 - val_accuracy: 0.8518\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.47015\n",
            "Epoch 82/200\n",
            "351/351 - 30s - loss: 0.4901 - accuracy: 0.8420 - val_loss: 0.5284 - val_accuracy: 0.8338\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.47015\n",
            "Epoch 83/200\n",
            "351/351 - 30s - loss: 0.4864 - accuracy: 0.8429 - val_loss: 0.5115 - val_accuracy: 0.8432\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.47015\n",
            "Epoch 84/200\n",
            "351/351 - 31s - loss: 0.4835 - accuracy: 0.8431 - val_loss: 0.4851 - val_accuracy: 0.8500\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.47015\n",
            "Epoch 85/200\n",
            "351/351 - 30s - loss: 0.4828 - accuracy: 0.8454 - val_loss: 0.4717 - val_accuracy: 0.8552\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.47015\n",
            "Epoch 86/200\n",
            "351/351 - 30s - loss: 0.4822 - accuracy: 0.8462 - val_loss: 0.5031 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.47015\n",
            "Epoch 87/200\n",
            "351/351 - 30s - loss: 0.4737 - accuracy: 0.8461 - val_loss: 0.4899 - val_accuracy: 0.8472\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.47015\n",
            "Epoch 88/200\n",
            "351/351 - 30s - loss: 0.4696 - accuracy: 0.8499 - val_loss: 0.4592 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.47015 to 0.45924, saving model to model.weights.best.hdf5\n",
            "Epoch 89/200\n",
            "351/351 - 30s - loss: 0.4696 - accuracy: 0.8485 - val_loss: 0.4812 - val_accuracy: 0.8492\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.45924\n",
            "Epoch 90/200\n",
            "351/351 - 30s - loss: 0.4690 - accuracy: 0.8489 - val_loss: 0.4925 - val_accuracy: 0.8484\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.45924\n",
            "Epoch 91/200\n",
            "351/351 - 30s - loss: 0.4664 - accuracy: 0.8488 - val_loss: 0.4668 - val_accuracy: 0.8562\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.45924\n",
            "Epoch 92/200\n",
            "351/351 - 30s - loss: 0.4669 - accuracy: 0.8508 - val_loss: 0.4625 - val_accuracy: 0.8566\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.45924\n",
            "Epoch 93/200\n",
            "351/351 - 30s - loss: 0.4607 - accuracy: 0.8529 - val_loss: 0.4692 - val_accuracy: 0.8532\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.45924\n",
            "Epoch 94/200\n",
            "351/351 - 30s - loss: 0.4590 - accuracy: 0.8520 - val_loss: 0.5033 - val_accuracy: 0.8492\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.45924\n",
            "Epoch 95/200\n",
            "351/351 - 30s - loss: 0.4532 - accuracy: 0.8553 - val_loss: 0.4917 - val_accuracy: 0.8452\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.45924\n",
            "Epoch 96/200\n",
            "351/351 - 30s - loss: 0.4522 - accuracy: 0.8560 - val_loss: 0.4539 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.45924 to 0.45388, saving model to model.weights.best.hdf5\n",
            "Epoch 97/200\n",
            "351/351 - 30s - loss: 0.4510 - accuracy: 0.8561 - val_loss: 0.4584 - val_accuracy: 0.8586\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.45388\n",
            "Epoch 98/200\n",
            "351/351 - 30s - loss: 0.4530 - accuracy: 0.8544 - val_loss: 0.4992 - val_accuracy: 0.8510\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.45388\n",
            "Epoch 99/200\n",
            "351/351 - 30s - loss: 0.4459 - accuracy: 0.8565 - val_loss: 0.4715 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.45388\n",
            "Epoch 100/200\n",
            "351/351 - 31s - loss: 0.4476 - accuracy: 0.8574 - val_loss: 0.4944 - val_accuracy: 0.8484\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.45388\n",
            "Epoch 101/200\n",
            "351/351 - 31s - loss: 0.4453 - accuracy: 0.8563 - val_loss: 0.4705 - val_accuracy: 0.8568\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.45388\n",
            "Epoch 102/200\n",
            "351/351 - 30s - loss: 0.4362 - accuracy: 0.8605 - val_loss: 0.4550 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.45388\n",
            "Epoch 103/200\n",
            "351/351 - 30s - loss: 0.4412 - accuracy: 0.8581 - val_loss: 0.4883 - val_accuracy: 0.8524\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.45388\n",
            "Epoch 104/200\n",
            "351/351 - 31s - loss: 0.4389 - accuracy: 0.8600 - val_loss: 0.4362 - val_accuracy: 0.8676\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.45388 to 0.43622, saving model to model.weights.best.hdf5\n",
            "Epoch 105/200\n",
            "351/351 - 30s - loss: 0.4360 - accuracy: 0.8615 - val_loss: 0.4584 - val_accuracy: 0.8562\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.43622\n",
            "Epoch 106/200\n",
            "351/351 - 30s - loss: 0.4356 - accuracy: 0.8605 - val_loss: 0.4476 - val_accuracy: 0.8630\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.43622\n",
            "Epoch 107/200\n",
            "351/351 - 30s - loss: 0.4378 - accuracy: 0.8607 - val_loss: 0.4461 - val_accuracy: 0.8682\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.43622\n",
            "Epoch 108/200\n",
            "351/351 - 30s - loss: 0.4300 - accuracy: 0.8638 - val_loss: 0.4633 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.43622\n",
            "Epoch 109/200\n",
            "351/351 - 30s - loss: 0.4321 - accuracy: 0.8604 - val_loss: 0.4787 - val_accuracy: 0.8516\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.43622\n",
            "Epoch 110/200\n",
            "351/351 - 30s - loss: 0.4272 - accuracy: 0.8638 - val_loss: 0.4564 - val_accuracy: 0.8588\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.43622\n",
            "Epoch 111/200\n",
            "351/351 - 30s - loss: 0.4284 - accuracy: 0.8639 - val_loss: 0.4725 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.43622\n",
            "Epoch 112/200\n",
            "351/351 - 30s - loss: 0.4286 - accuracy: 0.8629 - val_loss: 0.4599 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.43622\n",
            "Epoch 113/200\n",
            "351/351 - 30s - loss: 0.4161 - accuracy: 0.8673 - val_loss: 0.4637 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.43622\n",
            "Epoch 114/200\n",
            "351/351 - 30s - loss: 0.4221 - accuracy: 0.8649 - val_loss: 0.4624 - val_accuracy: 0.8620\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.43622\n",
            "Epoch 115/200\n",
            "351/351 - 30s - loss: 0.4240 - accuracy: 0.8630 - val_loss: 0.4355 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.43622 to 0.43546, saving model to model.weights.best.hdf5\n",
            "Epoch 116/200\n",
            "351/351 - 30s - loss: 0.4201 - accuracy: 0.8660 - val_loss: 0.4385 - val_accuracy: 0.8672\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.43546\n",
            "Epoch 117/200\n",
            "351/351 - 30s - loss: 0.4167 - accuracy: 0.8667 - val_loss: 0.4501 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.43546\n",
            "Epoch 118/200\n",
            "351/351 - 30s - loss: 0.4124 - accuracy: 0.8703 - val_loss: 0.4612 - val_accuracy: 0.8576\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.43546\n",
            "Epoch 119/200\n",
            "351/351 - 30s - loss: 0.4135 - accuracy: 0.8683 - val_loss: 0.4278 - val_accuracy: 0.8666\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.43546 to 0.42779, saving model to model.weights.best.hdf5\n",
            "Epoch 120/200\n",
            "351/351 - 30s - loss: 0.4106 - accuracy: 0.8687 - val_loss: 0.4628 - val_accuracy: 0.8576\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.42779\n",
            "Epoch 121/200\n",
            "351/351 - 30s - loss: 0.4082 - accuracy: 0.8697 - val_loss: 0.4421 - val_accuracy: 0.8640\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.42779\n",
            "Epoch 122/200\n",
            "351/351 - 30s - loss: 0.4115 - accuracy: 0.8700 - val_loss: 0.4337 - val_accuracy: 0.8700\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.42779\n",
            "Epoch 123/200\n",
            "351/351 - 30s - loss: 0.4090 - accuracy: 0.8706 - val_loss: 0.4606 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.42779\n",
            "Epoch 124/200\n",
            "351/351 - 30s - loss: 0.4013 - accuracy: 0.8735 - val_loss: 0.4191 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.42779 to 0.41906, saving model to model.weights.best.hdf5\n",
            "Epoch 125/200\n",
            "351/351 - 30s - loss: 0.4077 - accuracy: 0.8699 - val_loss: 0.4259 - val_accuracy: 0.8728\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.41906\n",
            "Epoch 126/200\n",
            "351/351 - 30s - loss: 0.4032 - accuracy: 0.8717 - val_loss: 0.4402 - val_accuracy: 0.8676\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.41906\n",
            "Epoch 127/200\n",
            "351/351 - 30s - loss: 0.4069 - accuracy: 0.8723 - val_loss: 0.4354 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.41906\n",
            "Epoch 128/200\n",
            "351/351 - 30s - loss: 0.4027 - accuracy: 0.8718 - val_loss: 0.4285 - val_accuracy: 0.8674\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.41906\n",
            "Epoch 129/200\n",
            "351/351 - 30s - loss: 0.3973 - accuracy: 0.8748 - val_loss: 0.4382 - val_accuracy: 0.8634\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.41906\n",
            "Epoch 130/200\n",
            "351/351 - 30s - loss: 0.3978 - accuracy: 0.8751 - val_loss: 0.4471 - val_accuracy: 0.8666\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.41906\n",
            "Epoch 131/200\n",
            "351/351 - 30s - loss: 0.3957 - accuracy: 0.8744 - val_loss: 0.4536 - val_accuracy: 0.8634\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.41906\n",
            "Epoch 132/200\n",
            "351/351 - 30s - loss: 0.3939 - accuracy: 0.8764 - val_loss: 0.4243 - val_accuracy: 0.8736\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.41906\n",
            "Epoch 133/200\n",
            "351/351 - 30s - loss: 0.3946 - accuracy: 0.8752 - val_loss: 0.4528 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.41906\n",
            "Epoch 134/200\n",
            "351/351 - 30s - loss: 0.3906 - accuracy: 0.8770 - val_loss: 0.4445 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.41906\n",
            "Epoch 135/200\n",
            "351/351 - 30s - loss: 0.3905 - accuracy: 0.8774 - val_loss: 0.4631 - val_accuracy: 0.8646\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.41906\n",
            "Epoch 136/200\n",
            "351/351 - 30s - loss: 0.3892 - accuracy: 0.8763 - val_loss: 0.4366 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.41906\n",
            "Epoch 137/200\n",
            "351/351 - 30s - loss: 0.3895 - accuracy: 0.8760 - val_loss: 0.4481 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.41906\n",
            "Epoch 138/200\n",
            "351/351 - 30s - loss: 0.3868 - accuracy: 0.8775 - val_loss: 0.4133 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.41906 to 0.41329, saving model to model.weights.best.hdf5\n",
            "Epoch 139/200\n",
            "351/351 - 30s - loss: 0.3849 - accuracy: 0.8786 - val_loss: 0.4310 - val_accuracy: 0.8722\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.41329\n",
            "Epoch 140/200\n",
            "351/351 - 30s - loss: 0.3830 - accuracy: 0.8799 - val_loss: 0.4146 - val_accuracy: 0.8752\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.41329\n",
            "Epoch 141/200\n",
            "351/351 - 30s - loss: 0.3804 - accuracy: 0.8802 - val_loss: 0.4304 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.41329\n",
            "Epoch 142/200\n",
            "351/351 - 30s - loss: 0.3844 - accuracy: 0.8785 - val_loss: 0.4278 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.41329\n",
            "Epoch 143/200\n",
            "351/351 - 30s - loss: 0.3860 - accuracy: 0.8766 - val_loss: 0.4179 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.41329\n",
            "Epoch 144/200\n",
            "351/351 - 29s - loss: 0.3773 - accuracy: 0.8823 - val_loss: 0.4272 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.41329\n",
            "Epoch 145/200\n",
            "351/351 - 30s - loss: 0.3786 - accuracy: 0.8803 - val_loss: 0.4221 - val_accuracy: 0.8748\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.41329\n",
            "Epoch 146/200\n",
            "351/351 - 30s - loss: 0.3794 - accuracy: 0.8807 - val_loss: 0.4130 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00146: val_loss improved from 0.41329 to 0.41298, saving model to model.weights.best.hdf5\n",
            "Epoch 147/200\n",
            "351/351 - 30s - loss: 0.3736 - accuracy: 0.8821 - val_loss: 0.4063 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.41298 to 0.40631, saving model to model.weights.best.hdf5\n",
            "Epoch 148/200\n",
            "351/351 - 30s - loss: 0.3756 - accuracy: 0.8814 - val_loss: 0.4297 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.40631\n",
            "Epoch 149/200\n",
            "351/351 - 30s - loss: 0.3727 - accuracy: 0.8830 - val_loss: 0.4141 - val_accuracy: 0.8772\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.40631\n",
            "Epoch 150/200\n",
            "351/351 - 30s - loss: 0.3797 - accuracy: 0.8815 - val_loss: 0.4392 - val_accuracy: 0.8638\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.40631\n",
            "Epoch 151/200\n",
            "351/351 - 30s - loss: 0.3722 - accuracy: 0.8840 - val_loss: 0.4274 - val_accuracy: 0.8674\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.40631\n",
            "Epoch 152/200\n",
            "351/351 - 30s - loss: 0.3686 - accuracy: 0.8859 - val_loss: 0.4482 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.40631\n",
            "Epoch 153/200\n",
            "351/351 - 30s - loss: 0.3716 - accuracy: 0.8822 - val_loss: 0.4226 - val_accuracy: 0.8694\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.40631\n",
            "Epoch 154/200\n",
            "351/351 - 30s - loss: 0.3685 - accuracy: 0.8842 - val_loss: 0.4259 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.40631\n",
            "Epoch 155/200\n",
            "351/351 - 31s - loss: 0.3678 - accuracy: 0.8836 - val_loss: 0.4352 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.40631\n",
            "Epoch 156/200\n",
            "351/351 - 30s - loss: 0.3655 - accuracy: 0.8857 - val_loss: 0.4107 - val_accuracy: 0.8760\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.40631\n",
            "Epoch 157/200\n",
            "351/351 - 30s - loss: 0.3646 - accuracy: 0.8848 - val_loss: 0.4227 - val_accuracy: 0.8760\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.40631\n",
            "Epoch 158/200\n",
            "351/351 - 30s - loss: 0.3660 - accuracy: 0.8848 - val_loss: 0.4309 - val_accuracy: 0.8728\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.40631\n",
            "Epoch 159/200\n",
            "351/351 - 30s - loss: 0.3661 - accuracy: 0.8844 - val_loss: 0.4222 - val_accuracy: 0.8770\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.40631\n",
            "Epoch 160/200\n",
            "351/351 - 30s - loss: 0.3618 - accuracy: 0.8855 - val_loss: 0.4043 - val_accuracy: 0.8786\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.40631 to 0.40428, saving model to model.weights.best.hdf5\n",
            "Epoch 161/200\n",
            "351/351 - 30s - loss: 0.3658 - accuracy: 0.8851 - val_loss: 0.4164 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.40428\n",
            "Epoch 162/200\n",
            "351/351 - 30s - loss: 0.3617 - accuracy: 0.8863 - val_loss: 0.4228 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.40428\n",
            "Epoch 163/200\n",
            "351/351 - 30s - loss: 0.3638 - accuracy: 0.8860 - val_loss: 0.3997 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.40428 to 0.39972, saving model to model.weights.best.hdf5\n",
            "Epoch 164/200\n",
            "351/351 - 30s - loss: 0.3620 - accuracy: 0.8855 - val_loss: 0.4392 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.39972\n",
            "Epoch 165/200\n",
            "351/351 - 30s - loss: 0.3576 - accuracy: 0.8878 - val_loss: 0.4011 - val_accuracy: 0.8780\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.39972\n",
            "Epoch 166/200\n",
            "351/351 - 30s - loss: 0.3596 - accuracy: 0.8872 - val_loss: 0.4125 - val_accuracy: 0.8772\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.39972\n",
            "Epoch 167/200\n",
            "351/351 - 30s - loss: 0.3538 - accuracy: 0.8889 - val_loss: 0.4397 - val_accuracy: 0.8722\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.39972\n",
            "Epoch 168/200\n",
            "351/351 - 30s - loss: 0.3515 - accuracy: 0.8898 - val_loss: 0.4186 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.39972\n",
            "Epoch 169/200\n",
            "351/351 - 30s - loss: 0.3555 - accuracy: 0.8890 - val_loss: 0.4100 - val_accuracy: 0.8788\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.39972\n",
            "Epoch 170/200\n",
            "351/351 - 30s - loss: 0.3575 - accuracy: 0.8867 - val_loss: 0.4242 - val_accuracy: 0.8780\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.39972\n",
            "Epoch 171/200\n",
            "351/351 - 30s - loss: 0.3478 - accuracy: 0.8925 - val_loss: 0.4152 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.39972\n",
            "Epoch 172/200\n",
            "351/351 - 30s - loss: 0.3496 - accuracy: 0.8895 - val_loss: 0.4190 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.39972\n",
            "Epoch 173/200\n",
            "351/351 - 31s - loss: 0.3536 - accuracy: 0.8886 - val_loss: 0.4075 - val_accuracy: 0.8770\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.39972\n",
            "Epoch 174/200\n",
            "351/351 - 30s - loss: 0.3511 - accuracy: 0.8906 - val_loss: 0.3921 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00174: val_loss improved from 0.39972 to 0.39213, saving model to model.weights.best.hdf5\n",
            "Epoch 175/200\n",
            "351/351 - 30s - loss: 0.3477 - accuracy: 0.8916 - val_loss: 0.4039 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.39213\n",
            "Epoch 176/200\n",
            "351/351 - 30s - loss: 0.3475 - accuracy: 0.8926 - val_loss: 0.4185 - val_accuracy: 0.8774\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.39213\n",
            "Epoch 177/200\n",
            "351/351 - 30s - loss: 0.3519 - accuracy: 0.8894 - val_loss: 0.4000 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.39213\n",
            "Epoch 178/200\n",
            "351/351 - 30s - loss: 0.3469 - accuracy: 0.8928 - val_loss: 0.3959 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.39213\n",
            "Epoch 179/200\n",
            "351/351 - 30s - loss: 0.3449 - accuracy: 0.8934 - val_loss: 0.3833 - val_accuracy: 0.8870\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.39213 to 0.38333, saving model to model.weights.best.hdf5\n",
            "Epoch 180/200\n",
            "351/351 - 30s - loss: 0.3441 - accuracy: 0.8918 - val_loss: 0.4105 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.38333\n",
            "Epoch 181/200\n",
            "351/351 - 30s - loss: 0.3452 - accuracy: 0.8931 - val_loss: 0.4159 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.38333\n",
            "Epoch 182/200\n",
            "351/351 - 30s - loss: 0.3426 - accuracy: 0.8931 - val_loss: 0.4159 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.38333\n",
            "Epoch 183/200\n",
            "351/351 - 30s - loss: 0.3488 - accuracy: 0.8915 - val_loss: 0.4468 - val_accuracy: 0.8718\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.38333\n",
            "Epoch 184/200\n",
            "351/351 - 30s - loss: 0.3405 - accuracy: 0.8942 - val_loss: 0.4040 - val_accuracy: 0.8788\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.38333\n",
            "Epoch 185/200\n",
            "351/351 - 30s - loss: 0.3368 - accuracy: 0.8947 - val_loss: 0.4108 - val_accuracy: 0.8788\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.38333\n",
            "Epoch 186/200\n",
            "351/351 - 30s - loss: 0.3503 - accuracy: 0.8906 - val_loss: 0.4037 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.38333\n",
            "Epoch 187/200\n",
            "351/351 - 30s - loss: 0.3383 - accuracy: 0.8958 - val_loss: 0.4001 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.38333\n",
            "Epoch 188/200\n",
            "351/351 - 30s - loss: 0.3413 - accuracy: 0.8942 - val_loss: 0.4146 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.38333\n",
            "Epoch 189/200\n",
            "351/351 - 30s - loss: 0.3390 - accuracy: 0.8953 - val_loss: 0.4012 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.38333\n",
            "Epoch 190/200\n",
            "351/351 - 30s - loss: 0.3399 - accuracy: 0.8940 - val_loss: 0.4368 - val_accuracy: 0.8718\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.38333\n",
            "Epoch 191/200\n",
            "351/351 - 30s - loss: 0.3410 - accuracy: 0.8936 - val_loss: 0.4182 - val_accuracy: 0.8720\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.38333\n",
            "Epoch 192/200\n",
            "351/351 - 30s - loss: 0.3361 - accuracy: 0.8957 - val_loss: 0.4108 - val_accuracy: 0.8762\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.38333\n",
            "Epoch 193/200\n",
            "351/351 - 30s - loss: 0.3338 - accuracy: 0.8968 - val_loss: 0.4068 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.38333\n",
            "Epoch 194/200\n",
            "351/351 - 30s - loss: 0.3347 - accuracy: 0.8946 - val_loss: 0.4161 - val_accuracy: 0.8776\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.38333\n",
            "Epoch 195/200\n",
            "351/351 - 30s - loss: 0.3369 - accuracy: 0.8965 - val_loss: 0.3987 - val_accuracy: 0.8814\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.38333\n",
            "Epoch 196/200\n",
            "351/351 - 30s - loss: 0.3346 - accuracy: 0.8958 - val_loss: 0.3752 - val_accuracy: 0.8862\n",
            "\n",
            "Epoch 00196: val_loss improved from 0.38333 to 0.37516, saving model to model.weights.best.hdf5\n",
            "Epoch 197/200\n",
            "351/351 - 30s - loss: 0.3275 - accuracy: 0.8966 - val_loss: 0.4037 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.37516\n",
            "Epoch 198/200\n",
            "351/351 - 30s - loss: 0.3330 - accuracy: 0.8978 - val_loss: 0.3987 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.37516\n",
            "Epoch 199/200\n",
            "351/351 - 30s - loss: 0.3309 - accuracy: 0.8976 - val_loss: 0.3929 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.37516\n",
            "Epoch 200/200\n",
            "351/351 - 30s - loss: 0.3312 - accuracy: 0.8969 - val_loss: 0.4420 - val_accuracy: 0.8724\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.37516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cBFIJSgGpKv"
      },
      "source": [
        "# **STEP 5: EVALUATE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIyVL8H5D-x5",
        "outputId": "de679169-935d-4868-87e2-dd23199dca4a"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 15ms/step - loss: 0.4937 - accuracy: 0.8631\n",
            "\n",
            "Test result: 86.310 loss: 0.494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdKHzdq9GvFv"
      },
      "source": [
        "# **Plot learning curves**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "U_0TUEO3D_eG",
        "outputId": "1b357765-79b0-4a7a-dcce-e6cc246c1cce"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfr/8fc9JT2ENEoSIKETaUJEQLFhAQuIrgiIYlt07W0Vd9W1/nTX1VV3WV30a1srIioqCiIIqxQpIj30EgIhpPdkZp7fH2eAIQYIkGQyyf26rlwz58zJnHvOTD555jnPOUeMMSillAp8Nn8XoJRSqm5ooCulVBOhga6UUk2EBrpSSjURGuhKKdVEOPy14ri4OJOcnOyv1SulVEBavnz5fmNMfE2P+S3Qk5OTWbZsmb9Wr5RSAUlEdhzpMe1yUUqpJkIDXSmlmggNdKWUaiL81odek6qqKjIyMigvL/d3KfUqJCSEpKQknE6nv0tRSjUhtQp0ERkGvAzYgTeMMc9Ve7wD8CYQD+QC440xGcdbTEZGBpGRkSQnJyMix/vrAcEYQ05ODhkZGaSkpPi7HKVUE3LMLhcRsQOTgeFAKjBWRFKrLfZ34F1jTG/gSeDZEymmvLyc2NjYJhvmACJCbGxsk/8WopRqeLXpQx8AbDbGbDXGVAIfASOrLZMKzPXen1fD47XWlMP8gObwGpVSDa82XS6JwC6f6Qzg9GrL/ApcgdUtMwqIFJFYY0xOnVSplFKNlDGGjLwyWoQ4iQpzUuFyU+nyEBnipLC8itUZBazclY8xhqiwIDrEhJGa0IK4iOA6r6Wudoo+APxLRK4HFgC7AXf1hURkIjARoH379nW06rqTn5/PBx98wG233XZcv3fxxRfzwQcf0LJly3qqTClVFwrLq8gprqRDTBg2m1BS4aK8yk14sIMQp51NWUXMS99HXmkVI/okEBcRzG3vLyc82EHPhCg2ZhUREx5E/w7RtGoRwo+bsvl8ZSbZRRUEO2yc2TmOn7flUlThIiLYQXGFq8Y6nhp5CtcOSq7z1yfHusCFiAwCHjfGXOSdfhjAGFNjP7mIRAAbjDFJR3vetLQ0U/1I0fXr19OjR4/aV1/Htm/fzqWXXsqaNWsOm+9yuXA46nZAkL9fq1KBqKzSTbDDhs1mdVt+smwXb/20nbuGduaiU9oA8MuufJZszWVtZgHr9xTSuVUEEwYl88J3G1m+Iw+AuIhgYsKdbMwqBiDYYaNXYhTLd+ZhDIhAiMNO6xbBZBVWEB8ZzK68UlLiwtlfVEFhuRXUdptwQY/WDO4cy7rMQual7+OMTnF0aR3J3oIy2rYMpXubSPp3iCbIYSOvpIodOSW0jw2jbVToCW0DEVlujEmr6bHapNRSoIuIpGC1vMcA46qtIA7INcZ4gIexRrwEnEmTJrFlyxb69u2L0+kkJCSE6OhoNmzYwMaNG7n88svZtWsX5eXl3H333UycOBE4dBqD4uJihg8fzplnnsnChQtJTEzkiy++IDT0xN44pZoTj8ccDGpjDIu25LBhbxEtw5z8tDmHRVv2k1lQTqjTTq+kKM7qEsc/5mwiyG7j1vdW0DYqhFCnne6537PXxJAV1YfubSL536b9zFqbRcswJw+c34lkWxbf7omguNLNJb0SaBnmZNv+EhZvzeGmM1KYeHZHAP7w3grW7C7gzetPY3CnWCpcHkKcdtwew46cEvYVVZASF07rFiG1fo1touy0iar98sfrmC10ABG5GHgJa9jim8aYZ0TkSWCZMWaGiPwOa2SLwepyud0YU3G05zxWC/2JL9eyLrPwBF7SkaUmtOAvl51yxMd9W+g//PADl1xyCWvWrDk4vDA3N5eYmBjKyso47bTTmD9/PrGxsYcFeufOnVm2bBl9+/Zl9OjRjBgxgvHjx/9mXdpCV02FMYZ56fv4ZFkGuSWVPHZZKpHBTn7ZlUdcRDA/pO9j0dYckmPDiYsIxiZCbEQQWYXlbNhTRGSIg+ziCtZmFhLqtBMbEYRNhG37Sw6uIzLEwdld4+nWOpLc0krmbtjHjpxSureJ5OOJg/h27R4WbsnBFOzmpb0TIDgS2+1LILI1GXmlfP7LbiY4vydyyT+geC9c8Tr0Hn3U1+VyeygsdxETHnT8G2XDTPjmQbjsJeh8/vH//lGcbAsdY8xMYGa1eY/53J8GTDuZIhujAQMGHDZW/JVXXuGzzz4DYNeuXWzatInY2NjDficlJYW+ffsC0L9/f7Zv395g9Sp1IipdHvYXV+ByG9rFhCIiGGP426x0duWWMqJPAk6HjQ17ilixM48WIU4KyqpYuGU/neIjcHsM6/YUEhcRBAgj//UTLs+hhqLdJvTvEM3KXfkUlbtwuT2UVLoJC7KT2rYFmQXlRAY7uHlICpVVbvKKyyioMEw8qyNDe7Qit6SSlLhwgh32g8/5yCWpLNyyn16huURt+YKr067k6tPaw+zpsNdAVSl8fR9c/R5J0WHcEf8rfPoQdDgTgiNh/l+h55Vgs9ewRSwOu80K830bICgcnKHwy38h5SxI7H/kDfrrx/D5H8B4YPpEuPUnaNEWqrxDlZ3110JvVEeK+jpaS7qhhIeHH7z/ww8/MGfOHBYtWkRYWBjnnHNOjWPJg4MP7bm22+2UlZU1SK1K1WTb/hIy8koxBnolRhEdHkSFy83irbks2ZrD0u25/LqrgEq3B4DOrSIYdWoiReUuXpu/hbAgO1+t2nPw+TrGhVNa6cZhF67tYWdpLlS5DS+O7sNlfRIoKnfxyvebiAkPYmiPVuSVVNG5VcRvuhnK87NwbvwS+/50GHwntGwPHje8fxVUFsONsyBrLaz5klZxXSH+HMAOBRmw4l3se1czJCwGVk8DVznkboPTb4Hl70DqSEjoC989Bu+OgFanwLI3of1guHY6bPwWpl7nnTcItnwPzjAY8HvYOAsW/xsQ6/mCI+HdkeBxgc1h3cZ1hdsWH/pnsHsFfHE7VJVB296w7gvrH8eFT8Lbl8LkAdbzFO2BqHZw648Q0qJe3u9GG+j+EBkZSVFRUY2PFRQUEB0dTVhYGBs2bGDx4sUNXJ1qjkxlCWUrphLW9RyIOfzIYmMMs9dlsXhrDhUuD60jQ9idX8qPqzYS2iIOp8POhr2Hf54jgx24PIaB7mUUSwT2NqfwRvL30KYX22LP5qtVmbw4ax19ZTM39+zOg4MjyFr5LUFVRUSGBRMWnQB9x8H2H2HaDXDRszDo0KiwmPAgHh/hbYx5PGCzQfq38PYkcFVAx7Ohx2WEzLgTSnNAbLD+Sxj1GmxbYIUrQPo3MPvPkLvVmu46DPqMgc9utZ4ntrMVkF0uAJsT5j0NC1+BikIYdAck9oOgCJjzOOxcDN0uhkteAEcwdL8MWqXCzAcO39hl+fDjPyAsxqrrw7FWEEenQP/rrfVFtIbvHoXVn1j1LH0DvnnImh+VZIX54Dth6F/A7oRxU2HNNHBXQWi09c/iu8esrph6oIHuIzY2ljPOOIOePXsSGhpK69atDz42bNgwXnvtNXr06EG3bt0YOHCgHytVTYHbYyiucBEVevg5fcqr3GQXlrErv5ytXz7P+PzX4FvYmzKKV1vcw97cAtwG8qucLNuRR1iQnVCnnZySSlKDslhgf5CPgyYyI/gyHr8sldSEKFxuD6t2F7C3oJzeOd9yxY7nrZUVhkNOCexxcNZVbzPhjAqqKp7DmbcJNgOboZ3YrGBzu6CqBH562erSAFjxDgz8gzUs5IDKEpj5R9jwNQy5D+b/zQq7pDSrRf3rhxDbBcZPt0Lvv1dYrWCAXqOtfxbTJ0JlEfzuTSjKglkPWy3rxP7WvOjkQ+tzVVrdIYjVL57k7Q457SbofbXV9eHbIrbZYOyHsGOR1cpOSoPPb7P+KYS0hBu/hdAY+GwibP/JWjaui/W7Ho8V5t/9BVZ9DFvmQpeL4Ir/WIHtqgSHT597yhDrx9eif8Epl0PHc47/Q3MMtdopWh8a47DFhtScXmuTkLUOIttYrTeAkv2w4Svoe40VSkewMauI5NhwglxF8OXdVsuyz1i2eFpz78crWZVRwJDOsbRtGcqegnLW7ylkZNln3OL4mpEVT/FyyGu0cxbyZVlvJjq+ZqlJJdW2HYPwVtA4IofcyvhBHXEIlLsNzi9uxb5mKkS0gdsXw7z/B10vguQhsGiy1Y2x7gtoP9Bqte5eBqdeC7MfhazVVtExneCsP4K70gryzucfCsTsdCv8yvKg71iY+zT8fq7VXbJ6GmQshfydVus7rivsT4ewOLhlAUQlWv3R6z6H02+FUO9xG6W5Viu6KBP6jLNavd89Ch3PhWs/s/5ZrPwQdi60vhEER9T9+1u4Bz69Gc64G7peeGh+9YAG65vEjLus973HCDj3T0ftiz9MVZnVrTTkfuh07gmVerSdohroftKcXmvAqyyFv3eBlLNh7AdWAL19KexbS9nZf8Ez+C7Cgx0UllexLbsEEUiJC+dfczfznwVbSYwK4d3oKXTMmo3152aY5U7jH/YbOa9vJ8b+eiNf2M5jdsvRjApfy407JyEYdnceS8KWqciZ97Cww23E//IKXda+bHU/uMph6w9W2CYNsLobug2HNZ9Cu4FW+LVIgsIMq/sgpiPkbLZatq1S4fJ/Wy3KA4qyrNZ2h8FWv/LRAsoYq9VbWQx/7woRrawQd4RAuwEQ2RZOHW/1Wf/yrtWqbtun9tu7oshq4Q95AOI6n9h71oRpoDdCzem1NkpZ66yQO8qIg+zCclqEOQlO/xI+mYBB+HzQJwzd+BQR+RvICetEeOEWRjtfYfgZabzxv63klVYd9hyjTk2kc8Z0bi96mb9XXcU0zzk8nrCYofnTMPE9CEoZbH0Fd4TCuI/g4+sgur3VJ7t5jvUkN8891I1Qsh/C46xQXf4WzHwQPFVWiGf8DPZguGcVfHSNNX3hM9bt1vkwcjL0uLRut+P0iVbXw+A74exJ9dN6Voc56WGLSjWoH1+CzF+svtLafJVd/yV8eQ/c+j9okXDs5TNXwpSzISwWznoQBt4KWIeFb80uIaFFMLt+eIv2K57jbcdwBoRl0ZFwQk05QxbeSAsp5JbKe1hbmsL3IQ/yEO9w7axI7on9mRFdSsiLSyM8fTot7JW0bXMGsuGfFCeeQVinP/JGtzb0TBwPa86FaTfC3hXQaajVb/zu5VaXzpgPrFEbm+dYwZ5w6qHaw+OsWxFIuxES06As1+qPzVoLFcVWi/nK163p7pdYy7tdYK+HP/eL/w5n3getutf9c6vjpoGuGpc9q+D7J6yv9EtOP2wEBWDtlFr2f1b/6oGv44v+DaX7rT7ii56xWq9f3QNrP7f6ds+6HwbdibHZmbY8g8gfX+V87KypSKDvtw/xeUYE72ensHLHfqpwcK9jGnc7plNsi+Bm91SqCu0sjx5GSpSdhB2fk9l9AqP73EZMeBBB2/czZO5TzEtLI3ntv5B0D6S/DsEtrBEV8+ZB8hAixn3MbUGHhsHS80rY9B2s/wpG/NMaQvfTyzD6XWsIX1Q7a+hb+9OtnXhH0rb3ofutfYb6RicfvuOwPsIcrL71ehqCp46fdrn4SXN6rbXm8cCbF1qt0zY9YdfPcNuiQ8FkDHx1r9XV0OEMuGEmZG+EyadBcBQYN9yz2mrZTv89nu6XkZ1fSOu981njSOX5qD8xf7fwY+gD5AW3ZUrbZ3hwx83Y3WWU2yJo7Sgh/bQn6bPobrbGn0+Ha/9N0JQzrOFq134O8d1g5QdW94LDe7yBqwJeHWz1T7dsD9fNgH3rIfkMsAdZ/dwpZ0NQ2G9frzFQnm/1ZRtj7Wg8sNNVqSM4WpeLXlNUNR7rZ1ijJC540urvdZXDL+8devyHZ60wb9sHdvwEO5fgWf4ObrFzj+ceqCxm++SRlHx+P1tDUhm4aTynb5/Ik8676eLewgu5d/Jh/3SSzB56nX8t/5wwmHbXv0VbWwEpMcGEB9npt/B27EFhdLnunwRFxsKVb1hD35KHWN05Zz1wKMzBun/pS9YOyFFTrLHi3S+GkChrKF234TWHOVjdJgd2TIpomKuTpoHuIz8/n3//+98n9LsvvfQSpaWldVxRM1Gy32qhLvi7d1jfGO+45dNgs/dAk60/wPy/UdJjNH9PfIkiWwv2vHUtrsWv8a2rP3vjB/GGYwxSkk2lEZ6WP9C3Qxxv3zCARx5+guBb5hLXMopBa58EBLp7dw62Px25dy1y22KYMMNa/7BnrX5ogOQz4YopR++ySBkC966BDoPqcyspdUza5eLjSKfPrY0DJ+iKi4ur1fL+fq2NxvYf4e1LMW16IntX80u/Z3mndBBbsksYW/YhY0rf5+mO73PHttspIJzLKp6inBAeif6Oa0veZmHEhRQMfphLB/c99rpKc62x4EERMOrV+n9tStUDHeVSS76nz73gggto1aoVU6dOpaKiglGjRvHEE09QUlLC6NGjycjIwO128+ijj5KVlUVmZibnnnsucXFxzJs3z98vxX+qymHvautcGgcOuCnYbY1RDrdOZOZZ+wWeOU9QdumreOb+lSB7JK69W8jxtOaqhYlEhmXTO6kl6fYB2ErfY+y2PxFj8ng75Tmub3MK405vT0LUcKh4giHHs0MuLAau/m89vGilGofGG+jfTLKCoS616QXDnzviw8899xxr1qxh5cqVzJ49m2nTpvHzzz9jjGHEiBEsWLCA7OxsEhIS+PrrrwHrHC9RUVG8+OKLzJs3r9Yt9IBVVWaNxugz5tDOypwtsHORdTDJ3KescdUhLa0uE+OBLXMxNjtZsQNYWxbL2UVf4xAPJe9eTRvJ43nX1ezsOI6h3WOY3r49qW1b4LDbwNMfnn+cLmXb4ZQruO+qMYfXoqMrlDpM4w10P5s9ezazZ8/m1FOtMcDFxcVs2rSJIUOGcP/99/PQQw9x6aWXMmTIkGM8UxNQkgPTfw89LoOt86xDxzfPsc6IZzzw8XjYt866v+xNa0hhi0TY+ytVpQXMiRnPruwCzslaztm2JeyIPJXtXW/k3BV34rKHMfGuZ4iKif/tem126DwU1n4G5z3S8K9bqQDTeAP9KC3phmCM4eGHH+aWW275zWMrVqxg5syZPPLIIwwdOpTHHnushmdoQn7+j3UWvANnwus6zDpR0v9esEJ83zo8YfHYZtyJQVjV82H+lx/Dj/v2s3R/HiEOG1cPaE9Z3wTsCRF0sjvoBJASgs1mrznMD7jgSesAmthODfFKlQpojTfQ/cD39LkXXXQRjz76KNdccw0RERHs3r0bp9OJy+UiJiaG8ePH07JlS954443DfrfRdLm4Kqxx0L5nwautGXdZw/Euft46c97PU6wTOaWOpLwohz9lDObu2GI6zHsGgNXhg3ml4hJe58/Mcqdx69T9wH5OSWjBLWd15MYzU2q+wnmv3x27lhYJtTv6Uymlge7L9/S5w4cPZ9y4cQwaZA1Fi4iI4L333mPz5s388Y9/xGaz4XQ6efVVa7TExIkTGTZsGAkJCf7fKVqWD6/0tVq3/a6r3e+U5Fg7MQsyrJM0OcOt84D88j6U5ZHZcyJxPc7m/o9XMnNNJl+Z3zPYNpj2QYWsZjDO+FZs7v8J3VunMqXQQf8O0cTWFOJKqXqjwxb9pF5f64r/wow7rK6RcR8febnsdGvnZXi8dbRlVTnEd7XO8QwUj/mMyhn3safcySWljxMWZKe00s1Dw7pzfo9WZBaUM6hjLEEOPZxBqYaiwxabmzWfWrc7FlonZcrfYe2k9D2zoKsS3hxmjVQ552HI2YzH5sRWmMHqNqPosXcGaz58lIGyjU+i7uYvQ1NZs7uQ8GA7t5zVEZtN6NI60i8vTylVMw30pqZ4H2ybD3HdrIsLpH9tnbi/8/nWWfwO9KlvmWudpa8sl/Lpt1FMS24oe4AbHN/yzPYLeSMsnYGeNXjsIdzyh/utQ9mVUo1aowt0YwxyIjvyAki9dnOt/cwaeXLx36zLen15t3XlmfSZ8OtHGEcwla16U7T4fYIlkt3ulnQv38XnoVdz9+jR9Gk3kSVhThw/ZcLcddhSR2iYKxUgahXoIjIMeBmwA28YY56r9nh74B2gpXeZScaYmcdbTEhICDk5OcTGxjbZUDfGkJOTQ0jIkS+scMIqiq2L3CamWefHju8O2Rug9xjYtxY+vxUBik0kYVTyrf1synuOImnn3/jdTY/hiD50DVV6XGadW+W0m+q+TqVUvThmoIuIHZgMXABkAEtFZIYxZp3PYo8AU40xr4pIKjATSD7eYpKSksjIyCA7O/t4fzWghISEkJSUVPdP/OM/rFO9jn7Xmk45G5Odzo9tr+OHgn20dk9jR2hPJslbhFUUccnYOwnuchYw7rfPFd8N/pR59HNxK6Ualdq00AcAm40xWwFE5CNgJOAb6AY4cBx2FJB5IsU4nU5SUlJO5FdV3nZY+E88Pa9iX4vexHsMc+Im8G1YBz77Ip+4iAguTnuYhy7qRmTFtbBtAcGdj3GUq4a5UgGlNoGeCOzymc4ATq+2zOPAbBG5EwgHzq/piURkIjARoH379sdbqzqa2Y9ixMYNGZcw/9nvCXHaKK/y0LV1TyaP68qwnm2w27zdWCFJ0LeGVrlSKqDV1U7RscDbxpgXRGQQ8F8R6WmM8fguZIyZAkwBaxx6Ha27+agotkapBIVbV7fZsdC6LdoL62cwxT6Wpbmh3HdBJ7IKyxnYMZZLerXFZmua+yOUUoerTaDvBtr5TCd55/m6CRgGYIxZJCIhQBywry6KVFiH8r9xvjVi5YZv4J1LYf/Ggw9vNkl8aB/BtJsGk5qgZyFUqjmqTaAvBbqISApWkI/ht3vRdgJDgbdFpAcQAjTtPZv1rSwffv0Q+l9vXcrsx5cgez0guCcPRMrzuMd1FyvcnfBgo0OHZKaOG0CrFvUwekYpFRCOGejGGJeI3AHMwhqS+KYxZq2IPAksM8bMAO4HXheRe7F2kF5v/HVOgaZi0WRY8DfrQsl9xmL+93d+iTyPhcWtuKP8I/7jGUnbweN4o18ineMjrPOHK6WatUZ1Lpdmz1VhXTG+bR94uQ+UF1hXhQd22DtwVekkzurbg362TZx13nCSYvXQe6WaGz2XSyDwuGHqBNj4DXmp1xKdv4MdZ/2DzC1rWLErnymeUTw//jQuPKUNcKq/q1VKNUIa6I2B2wUz74eN3+Bu0Z7odf+l1AQzfHYUZTKUC1Nb881lp5DQMtTflSqlGjENdH8r2A2fTICMpXDmvbxYMJTRq27E0+l8nu87mAEpMcRH6nnFlVLHpoHuT2X58N4VULCb/cNeZbacyZR5ayjoP5WnL+9Dih6pqZQ6Dhro9a2qHH54FrpeBO0HQdZa6xzkxgMfXQM5W1h3/ttc8bWd8qrVJLYM5a7ze+hh90qp46aBXt/m/AWWvAY/vQzRHaxzroS3gpAWmNxtLDjlKf7wrYOk6FD+fU0/OsdH6JGdSqkTooFenzZ9Z4V52o1gD4a9q+H0P+BZM52KvRu41fUw85cl07ddJFOu7a8HBSmlTooGen368SWI6QgXPXvw8m/7isq5eVlP1hbnMrx3ErPO60K3NjqeXCl18jTQ69r3T0L+Lhj+V9i5CM6892CYb8oq4vq3lpJbUslr153OBamtj/FkSilVexrodamyBJb8ByqLIaIVGDd0u5jyKjdf/prJk1+tI8RpZ+otg+iVpJd1U0rVLQ30urRhphXmYoNF/4KI1swpSOCht+aSU1JJatsWTLmuP0nRYf6uVCnVBGmg16VVH0NUO+g6DJa+zoaoM7j5vys4JaEF/xx7KoM6Nd1rpSql/E8HO9eVoizYMhd6XQWDbscd3oqnd/ZmaPdWTL9tMIM7x2mYK6XqlbbQ68qS16yDhfpeAzEpPNLpU5Ysz+D7y04h2GH3d3VKqWZAA70ulOXBz6/DKZfzdWY470xbxNIduVw/OJn2sdpfrpRqGNrlcrIKdsPsR6GyiLftv+P2D1aQW1rJ7ed05oELu/m7OqVUM6It9JPx8+vwzYNgPKxpdRmP/yxcndaOp0f1xKlXEFJKNTBNndoozoYf/wEVxYfmLX4VZj4AXS5iznlfcenOsVzVP4nnruylYa6U8gtNntpY/jbMeRzevsQazeKqgHn/DzoNZfnAl7ltVjGnp8TwzKheOpJFKeU3Gui1kfkLhMbA/o0w4w7YtgAqCtnXYwK/f38VidGhvDa+P0EO3ZxKKf/RPvTayPwFOg+FuK4w7xmoKMYERTBhfjhuj4f/m5BGdHiQv6tUSjVztWpSisgwEUkXkc0iMqmGx/8hIiu9PxtFJL/uS/WToiwoyoSEUyHtJnCEws6FLHKcxubcSl4b35+O8RH+rlIppY4d6CJiByYDw4FUYKyIpPouY4y51xjT1xjTF/gnML0+ivWLPSut27Z9ITwW02csAO/m9+GZUb0Y1CnWj8UppdQhtelyGQBsNsZsBRCRj4CRwLojLD8W+EvdlNcIZK4EBNr2BuDzqPHsce2n0xlXMjqtnX9rU0opH7XpckkEdvlMZ3jn/YaIdABSgLlHeHyiiCwTkWXZ2dnHW6t/ZP4CcV0gOJKt2cX86btsFibfwf3De/m7MqWUOkxdD8sYA0wzxrhretAYM8UYk2aMSYuPj6/jVdeTzF8g4VRcbg/3frySYKeNF0b30et+KqUandoE+m7At28hyTuvJmOAD0+2qEajcA8U74W2fXnzp238mlHA05f3pLVe+1Mp1QjVJtCXAl1EJEVEgrBCe0b1hUSkOxANLKrbEv3Iu0N0T3h3Xpi9kQtSW3NJr7Z+LkoppWp2zEA3xriAO4BZwHpgqjFmrYg8KSIjfBYdA3xkjDH1U6ofZK7EiI37FngIdth4amRPPRJUKdVo1erAImPMTGBmtXmPVZt+vO7KaiQyfyE3tAOLMir459hTaROlXS1KqcZLj1U/EmOoyljB/KIkLu+bwGV9EvxdkVJKHZUG+hFU5GXgLMtmW1AXnhjZ09/lKKXUMWmgH8FX31g9TOeeexFRoU4/V6OUUsemgV6DTYu+5OyNT1Nqj6TfgLP8XY5SStWKBvoBa6ZDwW48matInnU9hbYozA2zIEivCaqUCn5pjKMAABJYSURBVAx6+lyA4n0w7QZokUi5hFFiwkkf/hEdk07xd2VKKVVr2kIHyE63bouzCCvYxBPcwrn9evi3JqWUOk4a6GBdiQgoH/cZd3oeIKL3ZYQ47X4uSimljo8GOliB7gznnYwEvqzsx5X9k/xdkVJKHTftQwfM/o1k2JN49tt0BneKJa1DtL9LUkqp46aBDlTu3cCykhR+PySFh4Z11/O1KKUCUvPucsnZAhVFBJdksksSufeCrjjszXuTKKUCV/NtoRdlwb9Ow93xXOxAVIeehAU1382hlAp8zbc5mrMJjBv7ljkA9Ok7wM8FKaXUyWm+gZ63A4AKgnBjo3evU/1ckFJKnZxmHOjbMdi4q/J2Nna5GVuQnutcKRXYmm2nscnbTpbEsSn2HLqM0RNwKaUCX7NtoRfv3cxWVxx3nNtZR7YopZqEZptkJm8HmdKaYT3b+LsUpZSqE80y0KvKi2nhyiG4VScdqqiUajKaZaCvWPUrAB06p/q5EqWUqju1CnQRGSYi6SKyWUQmHWGZ0SKyTkTWisgHdVtm3Vr160oAuvfQa4UqpZqOY/Y3iIgdmAxcAGQAS0VkhjFmnc8yXYCHgTOMMXki0qq+Cj5Z+aWV7N2ZDnYIiuvk73KUUqrO1KaFPgDYbIzZaoypBD4CRlZb5vfAZGNMHoAxZl/dlll3Pl2xm25mO25nOITF+rscpZSqM7UJ9ERgl890hneer65AVxH5SUQWi8iwuiqwLhm3i7j5f2K0Yz727heDnlVRKdWE1NVOUQfQBTgHGAu8LiItqy8kIhNFZJmILMvOzq6jVdfertn/YmTVTNJTroPLX2vw9SulVH2qTaDvBtr5TCd55/nKAGYYY6qMMduAjVgBfxhjzBRjTJoxJi0+Pv5Eaz4xBbtpvfQ5/ufpTcLoF8CuwxWVUk1LbQJ9KdBFRFJEJAgYA8yotsznWK1zRCQOqwtmax3WedI8c5/BeNx81/EhIkOD/F2OUkrVuWMGujHGBdwBzALWA1ONMWtF5EkRGeFdbBaQIyLrgHnAH40xOfVV9Imo3DSX79z9OPO0NH+XopRS9aJW/Q7GmJnAzGrzHvO5b4D7vD+NT2EmIaV7WGe/iHu7NdoRlUopdVKaxZGirh1LAAhOGUiQo1m8ZKVUM9Qs0i1r3f8oN05S+53h71KUUqreNItA9+xcwlo6MqRb9eHzSinVdDT5QDdV5bQu2UB2yz6EBtn9XY5SStWbJh/oGYunEYSLyM6D/V2KUkrVq6Yd6MXZxC54hDWeZLoM+Z2/q1FKqXrVdAPdVQmf34qzqpjJLR+gVctIf1eklFL1qmkGutsFn94Em+fwuGsCyamn+bsipZSqd00z0Je9CetnsKHPJN53ncfZXRv4vDFKKeUHTS/QK0tgwfPQ4UzeNZcQEeygX/tof1ellFL1rukF+pL/QMk+zNBHWbBpP4M6xerRoUqpZqHpJd3K9yHlbLaG9iQjr0y7W5RSzUbTCvSqMsjZAu0HMj/duoCGBrpSqrloWoG+fyNgoFUPFmzKpmN8OO1iwvxdlVJKNYimFej71gNQEd2VxVtzOKuLts6VUs1H0wt0m5PlxTGUV3m0u0Up1aw0vUCP68Ivu0sA6NdBhysqpZqPphXo2euhVQ9WZeSTEhdOVKjT3xUppVSDaTqBXlEM+TshvgerMwrolRjl74qUUqpBNZ1Az04HoCCyM5kF5fRO0kBXSjUvTSfQdy4CYK2nPQC9k1r6sxqllGpwTSfQ13wKbfvyc34kInBKQgt/V6SUUg2qVoEuIsNEJF1ENovIpBoev15EskVkpffn5rov9ShytkDmCuh5JasyCugcH0F4sKNBS1BKKX87ZqCLiB2YDAwHUoGxIpJaw6IfG2P6en/eqOM6j27NdOu25xWszdQdokqp5qk2LfQBwGZjzFZjTCXwETCyfss6Tus+h3YDyXW0Iquwgh5ttbtFKdX81CbQE4FdPtMZ3nnVXSkiq0Rkmoi0q+mJRGSiiCwTkWXZ2dknUG4NyvIhaw10Pp/1ewoBNNCVUs1SXe0U/RJINsb0Br4D3qlpIWPMFGNMmjEmLT6+jg7L373cuk1K8wl0vX6oUqr5qU2g7wZ8W9xJ3nkHGWNyjDEV3sk3gP51U14tZCwDBBL7sS6zkFaRwcRGBDfY6pVSqrGoTaAvBbqISIqIBAFjgBm+C4hIW5/JEcD6uivxGDKWQnx3CIli3Z5C7W5RSjVbxwx0Y4wLuAOYhRXUU40xa0XkSREZ4V3sLhFZKyK/AncB19dXwdWKswI9KY1Kl4ct2cUa6EqpZqtWg7WNMTOBmdXmPeZz/2Hg4botrRZytkB5PiSdxuZ9xVS5jfafK6WarcA+UjT9a+s26TTSs3SEi1KqeQvcQN+zCuY+A50vgFY92LKvBLtNSI4N93dlSinlF4Eb6DPugLAYGPUaiLB1fzHtY8IIcgTuS1JKqZMRuOmXsxVOGQXhcQBs2VdCp3htnSulmq/ADXR3JdiDrLsew7acEjrGR/i5KKWU8p/ADXRPFditS8ztziuj0uXRFrpSqlkLzED3uMF4DrbQt2QXA9BJW+hKqWYsMAPdXWndelvoBwJdu1yUUs1ZgAf6gRZ6CdFhTmLCg/xYlFJK+VeABrrLurUdaqFrd4tSqrkL0EA/vMtl2/4SUuJ0h6hSqnkL8EAPoqzSTXZRBR1iw/xbk1JK+VmABnqVdWsPYldeKQDt9ZB/pVQzF5iB7jkQ6A525HgDPUZb6Eqp5i0wA92ny2Vnrga6UkpBwAa6T5dLbimRwQ6iw5z+rUkppfwsQAP90CiXHTkltIsJQ0T8W5NSSvlZgAa6t4Vuc7Izt1S7W5RSigAPdI/Nya68MtrrkEWllArUQLe6XHLLodLl0Ra6UkoR4IGeWWSdAkADXSmlahnoIjJMRNJFZLOITDrKcleKiBGRtLorsQYeK8h3a6ArpdRBxwx0EbEDk4HhQCowVkRSa1guErgbWFLXRf6Gt4W+p9iNCLRtGVLvq1RKqcauNi30AcBmY8xWY0wl8BEwsoblngL+CpTXYX01O9jl4iY+Iphgh73eV6mUUo1dbQI9EdjlM53hnXeQiPQD2hljvj7aE4nIRBFZJiLLsrOzj7vYg7yjXHYXukiMDj3x51FKqSbkpHeKiogNeBG4/1jLGmOmGGPSjDFp8fHxJ75Sb6DvKnSR0FIDXSmloHaBvhto5zOd5J13QCTQE/hBRLYDA4EZ9bpj1NvlsrPARaIGulJKAbUL9KVAFxFJEZEgYAww48CDxpgCY0ycMSbZGJMMLAZGGGOW1UvFcLCFXuKyaaArpZTXMQPdGOMC7gBmAeuBqcaYtSLypIiMqO8Ca+RtobuxaZeLUkp5OWqzkDFmJjCz2rzHjrDsOSdf1jF4qvDYnICQoEMWlVIKCNgjRatwiXW63KSWelCRUkpBwAZ6JS4chAfZaRFaqy8ZSinV5AVsoFdhJ6FlqJ4HXSmlvAI00F1UGIceVKSUUj4CNNArqfDYaRulga6UUgcEZKAbdyUVxq7XEVVKKR8BGegeVyVVxk5EiO4QVUqpAwIy0N1VlVTiIDJYA10ppQ4IzEB3VVCFQ1voSinlIyAD3VNVSZVxEBGsfehKKXVAYAa6yxqHHqFdLkopdVBABrpxV1GFg0jtclFKqYMCNNArrT50baErpdRBARnoBw79152iSil1SIAGepW20JVSqpqADHTxVOEWB8GOgCxfKaXqRUAmos1TBTannmlRKaV8BG6gO4L8XYZSSjUqARnoduPCZtdAV0opX4Eb6NpCV0qpwwReoBuDAw10pZSqLvAC3V0FgN2pga6UUr5qFegiMkxE0kVks4hMquHxW0VktYisFJEfRSS17kv1clcCYHcG19sqlFIqEB0z0EXEDkwGhgOpwNgaAvsDY0wvY0xf4G/Ai3Ve6QEeq4Xu0EBXSqnD1KaFPgDYbIzZaoypBD4CRvouYIwp9JkMB0zdlXi4qsoKQANdKaWqq82x84nALp/pDOD06guJyO3AfUAQcF5NTyQiE4GJAO3btz/eWgEoLSsjCnAGaR+6Ukr5qrOdosaYycaYTsBDwCNHWGaKMSbNGJMWHx9/QuspKS0DIChYW+hKKeWrNoG+G2jnM53knXckHwGXn0xRR1NWXg5AUHBIfa1CKaUCUm0CfSnQRURSRCQIGAPM8F1ARLr4TF4CbKq7Eg9XVm610IODQutrFUopFZCO2YdujHGJyB3ALMAOvGmMWSsiTwLLjDEzgDtE5HygCsgDJtRXweXeFnpwiHa5KKWUr1qdUNwYMxOYWW3eYz73767juo7oQJdLiHa5KKXUYQLuSNGKA4EeooGulFK+Ai/QK61ADw3VPnSllPIVcIHeNyEcgOAg7UNXSilfARfoiZF2AD3bolJKVRNwgX7gbIvoBS6UUuowARzoTv/WoZRSjUwABrp1+lwNdKWUOlwAB7p2uSillK/AC3SPy7rVQFdKqcMEXqBrl4tSStUo8AI9phOkjgS7jkNXSilftTqXS6PS/WLrRyml1GECr4WulFKqRhroSinVRGigK6VUE6GBrpRSTYQGulJKNREa6Eop1URooCulVBOhga6UUk2EGGP8s2KRbGDHCf56HLC/DsupS421Nq3r+Ghdx6+x1tbU6upgjImv6QG/BfrJEJFlxpg0f9dRk8Zam9Z1fLSu49dYa2tOdWmXi1JKNREa6Eop1UQEaqBP8XcBR9FYa9O6jo/Wdfwaa23Npq6A7ENXSin1W4HaQldKKVWNBrpSSjURARfoIjJMRNJFZLOITPJjHe1EZJ6IrBORtSJyt3f+4yKyW0RWen8a/GocIrJdRFZ717/MOy9GRL4TkU3e2+gGrqmbzzZZKSKFInKPv7aXiLwpIvtEZI3PvBq3kVhe8X7mVolIvwau63kR2eBd92ci0tI7P1lEyny23WsNXNcR3zsRedi7vdJF5KL6qusotX3sU9d2EVnpnd8g2+wo+VC/nzFjTMD8AHZgC9ARCAJ+BVL9VEtboJ/3fiSwEUgFHgce8PN22g7EVZv3N2CS9/4k4K9+fh/3Ah38tb2As4B+wJpjbSPgYuAbQICBwJIGrutCwOG9/1efupJ9l/PD9qrxvfP+HfwKBAMp3r9Ze0PWVu3xF4DHGnKbHSUf6vUzFmgt9AHAZmPMVmNMJfARMNIfhRhj9hhjVnjvFwHrgUR/1FJLI4F3vPffAS73Yy1DgS3GmBM9UvikGWMWALnVZh9pG40E3jWWxUBLEWnbUHUZY2YbY1zeycVAUn2s+3jrOoqRwEfGmApjzDZgM9bfboPXJiICjAY+rK/1H6GmI+VDvX7GAi3QE4FdPtMZNIIQFZFk4FRgiXfWHd6vTW82dNeGlwFmi8hyEZnondfaGLPHe38v0NoPdR0whsP/wPy9vQ440jZqTJ+7G7FacgekiMgvIjJfRIb4oZ6a3rvGtL2GAFnGmE0+8xp0m1XLh3r9jAVaoDc6IhIBfArcY4wpBF4FOgF9gT1YX/ca2pnGmH7AcOB2ETnL90Fjfcfzy3hVEQkCRgCfeGc1hu31G/7cRkciIn8GXMD73ll7gPbGmFOB+4APRKRFA5bUKN+7asZyeOOhQbdZDflwUH18xgIt0HcD7Xymk7zz/EJEnFhv1vvGmOkAxpgsY4zbGOMBXqcev2oeiTFmt/d2H/CZt4asA1/hvLf7Grour+HACmNMlrdGv28vH0faRn7/3InI9cClwDXeIMDbpZHjvb8cq6+6a0PVdJT3zu/bC0BEHMAVwMcH5jXkNqspH6jnz1igBfpSoIuIpHhbemOAGf4oxNs393/AemPMiz7zffu9RgFrqv9uPdcVLiKRB+5j7VBbg7WdJngXmwB80ZB1+TisxeTv7VXNkbbRDOA670iEgUCBz9fmeiciw4AHgRHGmFKf+fEiYvfe7wh0AbY2YF1Heu9mAGNEJFhEUrx1/dxQdfk4H9hgjMk4MKOhttmR8oH6/ozV997euv7B2hu8Ees/65/9WMeZWF+XVgErvT8XA/8FVnvnzwDaNnBdHbFGGPwKrD2wjYBY4HtgEzAHiPHDNgsHcoAon3l+2V5Y/1T2AFVY/ZU3HWkbYY08mOz9zK0G0hq4rs1Y/asHPmeveZe90vserwRWAJc1cF1HfO+AP3u3VzowvKHfS+/8t4Fbqy3bINvsKPlQr58xPfRfKaWaiEDrclFKKXUEGuhKKdVEaKArpVQToYGulFJNhAa6Uko1ERroSinVRGigK6VUE/H/AYJTLaG1UVhNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O97r8tsYEKJL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}